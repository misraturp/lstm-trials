{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [
                {
                    "execution_count": 2, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "0     After waiting what seemed like  G52   forever...\n1     Yeah   G15   it was such a change I  G40   sw...\n2       G13  And I was so glad that all of the meas...\n3     Ben and I had been saying for the past two we...\n4     Of course   G20  that is what happened for th...\nName: sentence, dtype: object"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "training_data length: 874\nlongest sentence: 150\nshortest sentence: 1\navrg sentence length: 27.0778032037\nstandard deviation of sentence length: 16.6001126717\nsentence length: 44.0\n"
                }
            ], 
            "source": "class data():\n    def __init__(self):\n        self.data = []\n        \nclass mini_data():\n    def __init__(self):\n        self.mini_data = []\n        \nd = data()\n\ndef read_data(sentence):\n    md = mini_data()\n    sentence = sentence.lower()\n    content = sentence.split()\n    new = md.mini_data + content\n    d.data.append(new)\n\ndf_data['sentence'].apply(read_data)\ntraining_data = np.array(d.data)\n\nprint('training_data length: ' + str(len(training_data)))\n\n\navrgs = [len(x) for x in training_data]\nprint('longest sentence: ' + str(np.max(avrgs)))\nprint('shortest sentence: ' + str(np.min(avrgs)))\nprint('avrg sentence length: ' + str(np.mean(avrgs)))\nprint('standard deviation of sentence length: ' + str(np.std(avrgs)))\n\n'''sentence length will be the average length plus the standard deviation'''\nsentence_length = round(np.mean(avrgs) + np.std(avrgs))\nprint('sentence length: ' + str(sentence_length))\n"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "3277\n"
                }, 
                {
                    "execution_count": 4, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "0"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "import collections\n\ndef build_dataset(words):\n    count = collections.Counter(words).most_common()\n    dictionary = dict()\n    for word, _ in count:\n        dictionary[word] = len(dictionary)\n    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n    return dictionary, reverse_dictionary\n\nwords = [item for sublist in training_data for item in sublist]\ndictionary, reverse_dictionary = build_dataset(words)\nvocab_size = len(dictionary)\n\n#print(dictionary)\nprint(vocab_size)\ndictionary['the']"
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "874\n44\n874\n57\n"
                }
            ], 
            "source": "train_input = []\ntrain_output = []\n\ndef create_input_output(sentence):\n    \n    prev_gesture = False\n    temp_out = [-1]*57\n    \n    '''create a 44-length array'''\n    single_input = [[-1]]*int(sentence_length)\n    single_output = [temp_out]*(int(sentence_length)+1)\n    loc = 0\n    \n    for j in range(0,len(sentence)):\n        \n        '''if the sentence does still have words'''\n        if j < int(sentence_length):\n            \n            word = sentence[j]\n            #print(word)\n            gesture = re.search(r'g\\d{1,2}',word)\n            \n            if gesture is None:\n                \n                if prev_gesture:\n                    \n                    prev_gesture = False\n                \n                single_output[loc] = temp_out\n                temp_out = [0]*57\n                num_word = dictionary[word]\n\n                single_input[loc] = [num_word]\n                loc = loc + 1\n                \n            else:                    \n                \n                num_gesture = int(word[1:])\n                del single_input[j]\n                single_input.append([-1])\n                temp_out[num_gesture] = 1\n                prev_gesture = True\n                \n                \n    train_input.append(single_input)\n    train_output.append(single_output)\n    return 'Done!'\n        \n#create_input_output(training_data[0])\nret_value = [create_input_output(sentence) for sentence in training_data]\nprint(len(train_input))\nprint(len(train_input[356]))\nprint(len(train_output))\nprint(len(train_output[48][34]))\n#print(train_input[0])\n#print(train_output[0][26])"
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[[69], [969], [112], [325], [68], [806], [2], [66], [155], [0], [278], [5], [487], [45], [2], [71], [31], [136], [47], [12], [0], [76], [61], [8], [572], [357], [1], [354], [112], [4], [499], [9], [7], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1]]\n44.0\n"
                }
            ], 
            "source": "print(train_input[0])\nprint(sentence_length)"
        }, 
        {
            "execution_count": 225, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "NUM_EXAMPLES = 800\ntest_input = train_input[NUM_EXAMPLES:]\ntest_output = train_output[NUM_EXAMPLES:] #everything beyond 800\n \ntrain_input = train_input[:NUM_EXAMPLES]\ntrain_output = train_output[:NUM_EXAMPLES] #till 800"
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from tensorflow.contrib import rnn\n\nnum_units = 25\nn_input = 4\ntime_steps = sentence_length / n_input\nlearning_rate = 0.001\nn_classes = 57\nbatch_size = 50\n"
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "out_weights = tf.Variable(tf.random_normal([num_units,n_classes]))\nout_bias = tf.Variable(tf.random_normal([n_classes]))\n\nx = tf.placeholder(\"float\", [None, time_steps, n_input])\ny = tf.placeholder(\"float\", [None, n_classes])"
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "input = tf.unstack(x, time_steps, 1)"
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "lstm_layer = rnn.BasicLSTMCell(num_units, forget_bias=1)\noutputs,_ = rnn.static_rnn(lstm_layer, input, dtype=\"float32\")"
        }, 
        {
            "execution_count": 13, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "prediction = tf.matmul(outputs[-1], out_weights) + out_bias"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}