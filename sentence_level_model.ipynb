{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!mkdir '../datasets/sentence_level_lstm'"
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "LSTM  LSTM_1  sentence_level_lstm\r\n"
                }
            ], 
            "source": "!ls '../datasets'"
        }, 
        {
            "execution_count": 210, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from io import StringIO\nimport requests\nimport pandas as pd\nimport numpy as np\nimport re, random, collections, json\nimport tensorflow as tf\nfrom tensorflow.contrib import rnn"
        }, 
        {
            "execution_count": 211, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 211, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "0     After waiting what seemed like  G52   forever...\n1     Yeah   G15   it was such a change! I  G40   s...\n2       G13  And I was so glad that all of the meas...\n3     Ben and I had been saying for the past two we...\n4     Of course   G20  that is what happened for th...\nName: sentence, dtype: object"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "execution_count": 212, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "longest sentence: 160\n"
                }
            ], 
            "source": "#get every sentence and put it into an array of separated words\nsentences_list = df_data.values.tolist()\nsentences_separated = [ re.findall(r\"[\\w']+|[.,!?;]\", sent[0].lower()) for sent in sentences]\nsentences_separated = np.array(sentences_separated)\n\navrgs = [len(x) for x in sentences_separated]\nmax_sentence_length = np.max(avrgs)\nprint('longest sentence: ' + str(max_sentence_length))"
        }, 
        {
            "execution_count": 213, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "3214\n"
                }
            ], 
            "source": "def filter_gestures(word):\n    ges = re.search(r'g\\d{1,2}',word)\n    if ges is None:\n        return True\n    else:\n        return False\n\ndef build_dictionary(words):\n    count = collections.Counter(words).most_common()\n    dictionary = dict()\n    for word, _ in count:\n        dictionary[word] = len(dictionary)+1\n    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n    return dictionary, reverse_dictionary\n\n'''make the list of list of words into list of words'''\nwords = [item for sublist in sentences_separated for item in sublist]\n\n'''filter the gesture annotations'''\nwords = [x for x in words if filter_gestures(x)]\n\n'''count the unique appearance of words and assign them a number'''\ndictionary, reverse_dictionary = build_dictionary(words)\n\n\n#print(dictionary)\nvocab_size = len(dictionary)\nprint(vocab_size)"
        }, 
        {
            "execution_count": 225, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "'''fixed variables'''\n#sequence length\ntime_steps=max_sentence_length\n\n#self explanatory\ninput_size=1\n\n#57 getsure types + no gesture\nn_classes=58\nno_gesture_index = n_classes - 1\n\n'''replaceable variables'''\n#could be any number\nnum_units=30\n\n#we need to learn about this\nlearning_rate=0.001\n\n#tbd\nbatch_size=20\n\n#number of iterations\nepoch = 800/batch_size"
        }, 
        {
            "execution_count": 226, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def populate_output(gesture_list):\n    \n    single_output = [0]*n_classes\n    \n    #if this is a no getsure sentence mark the last cell\n    if len(gesture_list) == 0:\n        single_output[no_gesture_index] = 1\n    \n    #else create their possiilities (try with giving them all 1 and then making them sum up to 1)\n    else:\n        #for a correct probability distribution\n        #count_gestures = len(gesture_list)\n        #value = 1/count_gestures\n        #for ges in gesture_list:\n        #    single_output[ges] = value\n        \n        #for a multiclass classification\n        for ges in gesture_list:\n            single_output[ges] = 1\n    \n    return single_output\n\ndef create_input_output(sentence):\n    \n    #create the max length of an empty array filled with 0s\n    single_input = [0]*max_sentence_length\n    loc = 0\n    \n    #create an array to keep the gesture information\n    gesture_list = []\n    \n    #for every word in the sentence\n    for word in sentence:\n        \n        #if word is not a gesture\n        gesture = re.search(r'g\\d{1,2}', word)\n        \n        if gesture is None:\n            \n            #find the encoded version of the word and add it to the corresponding space\n            encoded_word = dictionary[word]\n            single_input[loc] = encoded_word\n            loc = loc + 1\n            \n        #if the word is a gesture\n        else:\n\n            #add it to the gesture list\n            num_gesture = int(word[1:])\n            gesture_list.append(num_gesture)\n\n    #when the sentences traversing is done populat ethe output array for this specific input\n    single_output = populate_output(gesture_list)\n\n    return single_input, single_output\n"
        }, 
        {
            "execution_count": 227, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 227, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "874"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "model_data_input = []\nmodel_data_output = []\n\nfor sent in sentences_separated:\n    in_data, out_data = create_input_output(sent)\n    model_data_input.append(in_data)\n    model_data_output.append(out_data)\n    \nlen(model_data_input)"
        }, 
        {
            "execution_count": 228, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#Random sampling training and test data\n_TRAINING_INS_COUNT = 800\ntrain_indexes = random.sample(range(0, len(model_data_input)), _TRAINING_INS_COUNT)\ntest_indexes = [i for i in range(0, len(model_data_input)) if not i in train_indexes]\n\n\n#creating training data 80%\n_TRAINING_INPUT = np.array(model_data_input)\n_TRAINING_INPUT = _TRAINING_INPUT[train_indexes]\n_TRAINING_OUTPUT = np.array(model_data_output)\n_TRAINING_OUTPUT = _TRAINING_OUTPUT[train_indexes]\n\n\n#creating testing data 20%\n_TESTING_INPUT = np.array(model_data_input)\n_TESTING_INPUT = _TESTING_INPUT[test_indexes]\n_TESTING_OUTPUT = np.array(model_data_output)\n_TESTING_OUTPUT = _TESTING_OUTPUT[test_indexes]\n"
        }, 
        {
            "execution_count": 229, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "\ntf.reset_default_graph()\n\nout_weights=tf.Variable(tf.random_normal([num_units,n_classes]), name=\"weights\")\nout_bias=tf.Variable(tf.random_normal([n_classes]), name=\"biases\")\n\n#defining placeholders\n#input image placeholder\nx=tf.placeholder(\"float\",[None,time_steps,input_size])\n#input label placeholder\ny=tf.placeholder(\"float\",[None,n_classes])\n\n#processing the input tensor from [batch_size,n_steps,input_size] to \"time_steps\" number of [batch_size,input_size] tensors\ninput=tf.unstack(x ,time_steps,1)"
        }, 
        {
            "execution_count": 230, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Tensor(\"rnn/rnn/rnn/basic_lstm_cell/mul_479:0\", shape=(?, 30), dtype=float32)\n"
                }
            ], 
            "source": "# defining the network\nlstm_layer=rnn.BasicLSTMCell(num_units,forget_bias=1)\n\nwith tf.variable_scope(\"rnn\", reuse=None):\n    outputs,_=rnn.static_rnn(lstm_layer,input,dtype=\"float32\")\n    print(outputs[-1])\n    \n    #converting last output of dimension [batch_size,num_units] to [batch_size,n_classes] by out_weight multiplication\n    prediction=tf.matmul(outputs[-1],out_weights)+out_bias\n\n    #loss_function\n    loss=tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=prediction,labels=y))\n    #optimization\n    opt=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n\n    #model evaluationmatmul\n    correct_prediction=tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\n    accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
        }, 
        {
            "execution_count": 231, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#alternative model evaluation\ndef alternative_accuracy(raw_predictions, labels):\n    \n    accuracy_list = []\n    \n    for i in range(0,batch_size):\n        \n        #copy the prediction list for problem free manipulation\n        temp_predictions = raw_predictions[i]\n        \n        #if this is not a no gesture sentence\n        if labels[i][no_gesture_index] != 1:\n            \n            #get the number of gestures in this sentence\n            count_of_gestures = sum(labels[i])\n            \n            #array to keep the indices of max n predictions\n            predicted_indices = []\n            true_indices = []\n\n            #loop to get the highest n predicted indices\n            for j in range(0, count_of_gestures):\n                max_index = temp_predictions.index(max(temp_predictions))\n                predicted_indices.append(max_index)\n                temp_predictions[max_index] = -1000\n                \n            #loop to get the indices of actual values\n            for k in range(0,n_classes):\n                if labels[i][k] == 1:\n                    true_indices.append(k)\n            \n            #list of indices with the highes tpredictions = predicted_indices\n            #list of actual values = true_indices\n            \n            for prediction in predicted_indices:\n                if prediction in true_indices:\n                    accuracy_list.append(1)\n                else:\n                    accuracy_list.append(0)\n                    \n        #if this is a no getsure sentence:\n        else:\n            if temp_predictions[no_gesture_index] == 1:\n                accuracy_list.append(1)\n            else:\n                accuracy_list.append(0)\n            \n    batch_accuracy = np.mean(accuracy_list)\n    return batch_accuracy         \n    "
        }, 
        {
            "execution_count": 233, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Alternative accuracy  0.0175438596491\nFor iter  0\nAccuracy  0.0\nLoss  0.743864\n__________________\nAlternative accuracy  0.06\nFor iter  1\nAccuracy  0.0\nLoss  0.731054\n__________________\nAlternative accuracy  0.115384615385\nFor iter  2\nAccuracy  0.0\nLoss  0.731542\n__________________\nAlternative accuracy  0.0535714285714\nFor iter  3\nAccuracy  0.05\nLoss  0.732551\n__________________\nAlternative accuracy  0.0819672131148\nFor iter  4\nAccuracy  0.0\nLoss  0.742845\n__________________\nAlternative accuracy  0.0625\nFor iter  5\nAccuracy  0.0\nLoss  0.728739\n__________________\nAlternative accuracy  0.0757575757576\nFor iter  6\nAccuracy  0.0\nLoss  0.738041\n__________________\nAlternative accuracy  0.0425531914894\nFor iter  7\nAccuracy  0.0\nLoss  0.716666\n__________________\nAlternative accuracy  0.0833333333333\nFor iter  8\nAccuracy  0.0\nLoss  0.706484\n__________________\nAlternative accuracy  0.037037037037\nFor iter  9\nAccuracy  0.0\nLoss  0.709531\n__________________\nAlternative accuracy  0.0701754385965\nFor iter  10\nAccuracy  0.0\nLoss  0.704162\n__________________\nAlternative accuracy  0.0727272727273\nFor iter  11\nAccuracy  0.0\nLoss  0.697939\n__________________\nAlternative accuracy  0.0392156862745\nFor iter  12\nAccuracy  0.0\nLoss  0.692913\n__________________\nAlternative accuracy  0.148936170213\nFor iter  13\nAccuracy  0.0\nLoss  0.670627\n__________________\nAlternative accuracy  0.02\nFor iter  14\nAccuracy  0.0\nLoss  0.66592\n__________________\nAlternative accuracy  0.051724137931\nFor iter  15\nAccuracy  0.0\nLoss  0.667729\n__________________\nAlternative accuracy  0.0350877192982\nFor iter  16\nAccuracy  0.05\nLoss  0.644169\n__________________\nAlternative accuracy  0.0416666666667\nFor iter  17\nAccuracy  0.0\nLoss  0.628281\n__________________\nAlternative accuracy  0.111111111111\nFor iter  18\nAccuracy  0.0\nLoss  0.623317\n__________________\nAlternative accuracy  0.02\nFor iter  19\nAccuracy  0.0\nLoss  0.618316\n__________________\nAlternative accuracy  0.0169491525424\nFor iter  20\nAccuracy  0.0\nLoss  0.604317\n__________________\nAlternative accuracy  0.0344827586207\nFor iter  21\nAccuracy  0.0\nLoss  0.604495\n__________________\nAlternative accuracy  0.0444444444444\nFor iter  22\nAccuracy  0.0\nLoss  0.583043\n__________________\nAlternative accuracy  0.05\nFor iter  23\nAccuracy  0.0\nLoss  0.59113\n__________________\nAlternative accuracy  0.0188679245283\nFor iter  24\nAccuracy  0.0\nLoss  0.573215\n__________________\nAlternative accuracy  0.0\nFor iter  25\nAccuracy  0.0\nLoss  0.57274\n__________________\nAlternative accuracy  0.0192307692308\nFor iter  26\nAccuracy  0.0\nLoss  0.542959\n__________________\nAlternative accuracy  0.0338983050847\nFor iter  27\nAccuracy  0.0\nLoss  0.546863\n__________________\nAlternative accuracy  0.0\nFor iter  28\nAccuracy  0.0\nLoss  0.53114\n__________________\nAlternative accuracy  0.0\nFor iter  29\nAccuracy  0.0\nLoss  0.533484\n__________________\nAlternative accuracy  0.0652173913043\nFor iter  30\nAccuracy  0.0\nLoss  0.493172\n__________________\nAlternative accuracy  0.0344827586207\nFor iter  31\nAccuracy  0.0\nLoss  0.505198\n__________________\nAlternative accuracy  0.0181818181818\nFor iter  32\nAccuracy  0.0\nLoss  0.477403\n__________________\nAlternative accuracy  0.0384615384615\nFor iter  33\nAccuracy  0.0\nLoss  0.480003\n__________________\nAlternative accuracy  0.02\nFor iter  34\nAccuracy  0.05\nLoss  0.472338\n__________________\nAlternative accuracy  0.0192307692308\nFor iter  35\nAccuracy  0.05\nLoss  0.463333\n__________________\nAlternative accuracy  0.0208333333333\nFor iter  36\nAccuracy  0.0\nLoss  0.446934\n__________________\nAlternative accuracy  0.119402985075\nFor iter  37\nAccuracy  0.05\nLoss  0.456433\n__________________\nAlternative accuracy  0.0322580645161\nFor iter  38\nAccuracy  0.0\nLoss  0.447036\n__________________\nAlternative accuracy  0.0588235294118\nFor iter  39\nAccuracy  0.05\nLoss  0.430704\n__________________\nTesting Accuracy: 0.027027\n"
                }
            ], 
            "source": "#initialize variables\nbatch_init = 0\nlimit = batch_init + batch_size\ninit=tf.global_variables_initializer()\n#saver = tf.train.Saver()\n\nwith tf.Session() as sess:\n    \n    sess.run(init)\n    iter=0\n    while iter<epoch:\n        \n        batch_x = _TRAINING_INPUT[batch_init: limit]\n        batch_y = _TRAINING_OUTPUT[batch_init: limit]\n        batch_init = batch_init + batch_size\n        limit = batch_init + batch_size\n\n        batch_x=batch_x.reshape((batch_size,time_steps,input_size))\n\n        sess.run(opt, feed_dict={x: batch_x, y: batch_y})\n        #print(sess.run(esselamualeykum,feed_dict={x:batch_x,y:batch_y}))\n        \n        raw_predictions = prediction.eval(feed_dict={x: batch_x}, session=sess).tolist()\n        #results = [sublist.index(max(sublist)) for sublist in raw_predictions]\n        #print(results)\n        alt_acc = alternative_accuracy(raw_predictions, batch_y)\n        print(\"Alternative accuracy \", str(alt_acc))\n\n        if iter %1==0:\n            acc=sess.run(accuracy,feed_dict={x:batch_x,y:batch_y})\n            los=sess.run(loss,feed_dict={x:batch_x,y:batch_y})\n            print(\"For iter \",iter)\n            print(\"Accuracy \",acc)\n            print(\"Loss \",los)\n            print(\"__________________\")\n\n        iter=iter+1        \n    \n    #save_path = saver.save(sess,\"../datasets/LSTM_1/model.ckpt\")\n    #print(save_path)\n\n    #calculating test accuracy\n    test_data = _TESTING_INPUT.reshape((-1, time_steps, input_size))\n    test_label = _TESTING_OUTPUT\n    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: test_data, y: test_label}))\n    raw_predictions_test = prediction.eval(feed_dict={x: test_data}, session=sess).tolist()\n    alt_acc_test = alternative_accuracy(raw_predictions, batch_y)\n    print(\"Alternative accuracy for the test \", str(alt_acc_test))\n        \n    #print(\"Prediction:\", sess.run(prediction, feed_dict={x: test_data, y: test_label}))\n    #d = prediction.eval(feed_dict={x: test_data}, session=sess)\n    #print (\"predictions\", d)\n    #print(type(d[0]))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}